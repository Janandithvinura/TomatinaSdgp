{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb15390f",
   "metadata": {},
   "source": [
    "# 1. Load the dataset and pre-process the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90bfa3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "925ce2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the dataset\n",
    "dataset_path = \"C:/Users/Dell/Desktop/New_Tomato/PlantVillage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc6a811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image size and batch size\n",
    "image_size = (256, 256)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20a0bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02bc1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6679d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51ee83c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1925 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('train_data',\n",
    "target_size=(224,224),\n",
    "batch_size= 64,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65142d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 642 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = test_datagen.flow_from_directory('val_data',\n",
    "target_size=(224, 224),\n",
    "batch_size= 64,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b59e085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 641 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('test_data',\n",
    "target_size=(224, 224),\n",
    "batch_size= 64,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f0a0f",
   "metadata": {},
   "source": [
    "# 2. Load the pre-trained MobileNetV2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2645bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(weights=\"imagenet\",\n",
    "                         input_shape=(224, 224, 3), \n",
    "                         include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "273b2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f755a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers\n",
    "num_classes = 6\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bbc9dd",
   "metadata": {},
   "source": [
    "# 3.Train the model with fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7abd3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "764a7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eef6f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33c303bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "860/860 [==============================] - 989s 1s/step - loss: 0.4371 - accuracy: 0.8421 - val_loss: 3.2242 - val_accuracy: 0.4328\n",
      "Epoch 2/20\n",
      "860/860 [==============================] - 910s 1s/step - loss: 0.1443 - accuracy: 0.9529 - val_loss: 1.4615 - val_accuracy: 0.6866\n",
      "Epoch 3/20\n",
      "860/860 [==============================] - 912s 1s/step - loss: 0.0935 - accuracy: 0.9697 - val_loss: 1.2331 - val_accuracy: 0.7164\n",
      "Epoch 4/20\n",
      "860/860 [==============================] - 959s 1s/step - loss: 0.0753 - accuracy: 0.9769 - val_loss: 1.1136 - val_accuracy: 0.7164\n",
      "Epoch 5/20\n",
      "860/860 [==============================] - 948s 1s/step - loss: 0.0600 - accuracy: 0.9814 - val_loss: 1.1569 - val_accuracy: 0.6866\n",
      "Epoch 6/20\n",
      "860/860 [==============================] - 926s 1s/step - loss: 0.0582 - accuracy: 0.9820 - val_loss: 1.6779 - val_accuracy: 0.7313\n",
      "Epoch 7/20\n",
      "860/860 [==============================] - 986s 1s/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 1.2463 - val_accuracy: 0.7164\n",
      "Epoch 8/20\n",
      "860/860 [==============================] - 954s 1s/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 1.6405 - val_accuracy: 0.6269\n",
      "Epoch 9/20\n",
      "860/860 [==============================] - 892s 1s/step - loss: 0.0410 - accuracy: 0.9880 - val_loss: 0.9373 - val_accuracy: 0.7164\n",
      "Epoch 10/20\n",
      "860/860 [==============================] - 884s 1s/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 1.2631 - val_accuracy: 0.6866\n",
      "Epoch 11/20\n",
      "860/860 [==============================] - 912s 1s/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.9930 - val_accuracy: 0.7463\n",
      "Epoch 12/20\n",
      "860/860 [==============================] - 1008s 1s/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.9395 - val_accuracy: 0.6866\n",
      "Epoch 13/20\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9911"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Dell/Desktop/Tomato Leaf disease detection/dataset2/valid\\\\Tomato Early blight\\\\TomatoEarlyBlight(10).JPG'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1039, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 901, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1048, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Dell/Desktop/Tomato Leaf disease detection/dataset2/valid\\\\Tomato Early blight\\\\TomatoEarlyBlight(10).JPG'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_test_function_48850]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtraining_set\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtest_set\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mUnknownError\u001B[0m: Graph execution error:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Dell/Desktop/Tomato Leaf disease detection/dataset2/valid\\\\Tomato Early blight\\\\TomatoEarlyBlight(10).JPG'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1039, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 901, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1048, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 422, in load_img\n    with open(path, \"rb\") as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Dell/Desktop/Tomato Leaf disease detection/dataset2/valid\\\\Tomato Early blight\\\\TomatoEarlyBlight(10).JPG'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_test_function_48850]"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_set,\n",
    "                    validation_data= validation_set,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=len(training_set),\n",
    "                    validation_steps=len(validation_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c31d1b",
   "metadata": {},
   "source": [
    "# 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac15d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(history.history['val_accuracy'],linewidth = 4)\n",
    "plt.plot(history.history['accuracy'],linewidth = 4)\n",
    "\n",
    "plt.title(\"Training and Validation Accuracy\",fontsize=12)\n",
    "plt.ylabel(\"Accuracy\",fontsize=12)\n",
    "plt.xlabel(\"Number of epochs\",fontsize=12)\n",
    "plt.legend(['val','train'],loc = 'lower right')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(history.history['loss'],linewidth = 4)\n",
    "plt.plot(history.history['val_loss'],linewidth = 4)\n",
    "\n",
    "plt.title(\"Training and Validation Loss\",fontsize=12)\n",
    "plt.ylabel(\"Loss\",fontsize=12)\n",
    "plt.xlabel(\"Number of epochs\",fontsize=12)\n",
    "plt.legend(['train','val'],loc = 'upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "911f1a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 157s 831ms/step - loss: 0.3362 - accuracy: 0.8993\n",
      "Validation loss: 0.3362, Validation accuracy: 0.8993\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "val_loss, val_acc = model.evaluate(training_set)\n",
    "print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb492562",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m\n\u001B[0;32m      2\u001B[0m img_test \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset/val/Tomato___Tomato_Yellow_Leaf_Curl_Virus/1bef6514-c4be-4417-a390-3c506d4f1404___UF.GRC_YLCV_Lab 02020.JPG\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m img_resize \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#plt.imshow(mpimg.imread('dataset/val/Tomato___Tomato_Yellow_Leaf_Curl_Virus/1bef6514-c4be-4417-a390-3c506d4f1404___UF.GRC_YLCV_Lab 02020.JPG'))\u001B[39;00m\n\u001B[0;32m      5\u001B[0m img_scaled \u001B[38;5;241m=\u001B[39m img_resize\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img_test = cv2.imread('dataset/val/Tomato___Tomato_Yellow_Leaf_Curl_Virus/1bef6514-c4be-4417-a390-3c506d4f1404___UF.GRC_YLCV_Lab 02020.JPG')\n",
    "img_resize = cv2.resize(img_test,(256,256))\n",
    "#plt.imshow(mpimg.imread('dataset/val/Tomato___Tomato_Yellow_Leaf_Curl_Virus/1bef6514-c4be-4417-a390-3c506d4f1404___UF.GRC_YLCV_Lab 02020.JPG'))\n",
    "img_scaled = img_resize/255\n",
    "\n",
    "#BGR to RGB\n",
    "img_rgb = np.flip(img_scaled, axis=-1)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "img_reshaped = np.reshape(img_rgb,[1,256,256,3])\n",
    "#img_array = img_to_array(img_rgb) #It is better to use these two lines instead of img_reshaped = np.reshape(img_rgb,[1,256,256,3]). Both give same result but these do not depend on the scenario.\n",
    "#img_reshaped = img_array.reshape((1,) + img_array.shape)\n",
    "\n",
    "input_pred = model.predict(img_reshaped)\n",
    "print(input_pred)\n",
    "input_label = np.argmax(input_pred)\n",
    "print(input_label)\n",
    "\n",
    "\n",
    "if input_label == 0:\n",
    "    print(\"Early_blight\")\n",
    "elif input_label == 1:\n",
    "    print(\"Healthy\")\n",
    "elif input_label == 2:\n",
    "    print(\"Late_blight\")\n",
    "elif input_label == 3:\n",
    "    print(\"Septoria_leaf_spot\")\n",
    "elif input_label == 4:\n",
    "    print(\"Target_Spot\")\n",
    "elif input_label == 5:\n",
    "    print(\"Tomato_Yellow_Leaf_Curl_Virus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02691e69",
   "metadata": {},
   "source": [
    "# 5. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb17ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the version string for the saved model\n",
    "version = \"1.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca61cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with version details\n",
    "model.save(f\"tomato_disease_classifier_v{version.replace('.', '_')}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0326ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpl_iba472\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpl_iba472\\assets\n"
     ]
    }
   ],
   "source": [
    "# Load the saved Keras model\n",
    "model = tf.keras.models.load_model(\"tomato_disease_classifier_v1_0_0.h5\")\n",
    "\n",
    "# Convert the model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open(\"tomato_disease_classifier_v1_0_0.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6dfd27f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load the saved model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtomato_disease_classifier_v_1_0_0.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = load_model(\"tomato_disease_classifier_v_1_0_0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a305ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test images\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test images\n",
    "test_predictions = model.predict(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf9bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
